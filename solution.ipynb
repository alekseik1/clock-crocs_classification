{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedShuffleSplit, train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor i in os.listdir(CROC_PATH):\\n    if DEBUG: print('Reading image `{}`'.format(i))\\n    arr = cv2.imread(CROC_PATH + i)\\n    croc_dict[i.replace('.png', '')] = arr\\n    croc_data = np.append(croc_data, arr)\\nfor i in os.listdir(CLOCK_PATH):\\n    arr = cv2.imread(CLOCK_PATH + i)\\n    clock_dict[i.replace('.png', '')] = arr\\n    np.append(croc_data, arr)\\n\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CROC_PATH = 'data/crocodile/'\n",
    "CLOCK_PATH = 'data/clock/'\n",
    "DEBUG = False\n",
    "croc_dict = dict()\n",
    "clock_dict = dict()\n",
    "croc_data = np.array([cv2.imread(CROC_PATH + i) for i in os.listdir(CROC_PATH)])\n",
    "clock_data = np.array([cv2.imread(CLOCK_PATH + i) for i in os.listdir(CLOCK_PATH)])\n",
    "'''\n",
    "for i in os.listdir(CROC_PATH):\n",
    "    if DEBUG: print('Reading image `{}`'.format(i))\n",
    "    arr = cv2.imread(CROC_PATH + i)\n",
    "    croc_dict[i.replace('.png', '')] = arr\n",
    "    croc_data = np.append(croc_data, arr)\n",
    "for i in os.listdir(CLOCK_PATH):\n",
    "    arr = cv2.imread(CLOCK_PATH + i)\n",
    "    clock_dict[i.replace('.png', '')] = arr\n",
    "    np.append(croc_data, arr)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим простые модели и оценим их качество."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейная модель (можно пропустить при выполнении кода)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = np.concatenate((np.ones(clock_data.shape[0]), np.zeros(croc_data.shape[0])))\n",
    "data = np.concatenate((clock_data.reshape(clock_data.shape[0], -1), croc_data.reshape(croc_data.shape[0], -1)))\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, ans, test_size=0.3, random_state=0)\n",
    "cv = StratifiedShuffleSplit(n_splits=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression(random_state=0)\n",
    "param_grid = {'penalty': ['l1', 'l2'], 'C': [1, 10, 100]}\n",
    "grid_cv = GridSearchCV(reg, param_grid, scoring='accuracy', cv=cv, n_jobs=4)\n",
    "%time grid_cv.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты не очень. Попробуем другие классификаторы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RandomForestClassifier(random_state=0, n_jobs=4)\n",
    "param_grid = {'n_estimators': [600],\n",
    "              'max_depth': [30], 'criterion': ['entropy']}\n",
    "grid_cv = GridSearchCV(reg, param_grid, scoring='accuracy', cv=cv, n_jobs=4)\n",
    "%time grid_cv.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный бустинг над случайными лесами (тоже можно пропустить)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = xgb.XGBClassifier(random_state=0, learning_rate=0.005, n_jobs=4, n_estimators=300)\n",
    "#param_grid = {'n_estimators': [100, 200, 400, 600],\n",
    "#              'learning_rate': [0.001, 0.005, 0.1]}\n",
    "param_grid = {'n_estimators': [400],\n",
    "              'learning_rate': [0.005]}\n",
    "grid_cv = GridSearchCV(reg, param_grid, scoring='accuracy', cv=cv, n_jobs=4)\n",
    "%time grid_cv.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(reg, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## А теперь изюминка нашего проекта: CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ans = np.concatenate((np.ones(clock_data.shape[0]), np.zeros(croc_data.shape[0])))\n",
    "data = np.concatenate((clock_data, croc_data))\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, ans, test_size=0.2, random_state=42)\n",
    "#cv = StratifiedShuffleSplit(n_splits=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 32, 32, 3)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры модели. С ними надо будет поиграться\n",
    "batch_size = 15\n",
    "num_epochs = 28\n",
    "kernel_size = 3\n",
    "pool_size = 2\n",
    "conv_depth_1 = 32\n",
    "conv_depth_2 = 32\n",
    "drop_prob_1 = 0.3\n",
    "drop_prob_2 = 0.4\n",
    "hidden_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train, depth, height, width = train_data.shape\n",
    "num_test = test_data.shape[0]\n",
    "num_classes = np.unique(train_labels).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.astype('float32')\n",
    "test_data = test_data.astype('float32')\n",
    "train_data /= np.max(train_data)\n",
    "test_data /= np.max(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(train_labels, num_classes)\n",
    "Y_test = np_utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(depth, height, width))\n",
    "\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "conv_1 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(inp)\n",
    "#conv_2 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_1)\n",
    "drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "conv_3 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(drop_1)\n",
    "#conv_4 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_3)\n",
    "drop_2 = Dropout(drop_prob_2)(pool_2)\n",
    "\n",
    "# Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
    "flat = Flatten()(drop_2)\n",
    "hidden = Dense(hidden_size, activation='tanh')(flat)\n",
    "drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "out = Dense(num_classes, activation='softmax')(drop_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model = Model(input=inp, output=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720 samples, validate on 80 samples\n",
      "Epoch 1/28\n",
      "720/720 [==============================] - 2s 3ms/step - loss: 0.7232 - acc: 0.5792 - val_loss: 0.6376 - val_acc: 0.6625\n",
      "Epoch 2/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.6182 - acc: 0.6319 - val_loss: 0.6399 - val_acc: 0.6375\n",
      "Epoch 3/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.5364 - acc: 0.7389 - val_loss: 0.4795 - val_acc: 0.7625\n",
      "Epoch 4/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.4326 - acc: 0.7958 - val_loss: 0.3959 - val_acc: 0.8375\n",
      "Epoch 5/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.4022 - acc: 0.8347 - val_loss: 0.4667 - val_acc: 0.7375\n",
      "Epoch 6/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3300 - acc: 0.8597 - val_loss: 0.2626 - val_acc: 0.9000\n",
      "Epoch 7/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.2928 - acc: 0.8778 - val_loss: 0.2496 - val_acc: 0.9250\n",
      "Epoch 8/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.2598 - acc: 0.9028 - val_loss: 0.2895 - val_acc: 0.8500\n",
      "Epoch 9/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.2692 - acc: 0.8875 - val_loss: 0.2355 - val_acc: 0.9125\n",
      "Epoch 10/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.2310 - acc: 0.9083 - val_loss: 0.2395 - val_acc: 0.8875\n",
      "Epoch 11/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.2204 - acc: 0.9139 - val_loss: 0.3529 - val_acc: 0.8000\n",
      "Epoch 12/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.2353 - acc: 0.9028 - val_loss: 0.3350 - val_acc: 0.8375\n",
      "Epoch 13/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.2007 - acc: 0.9208 - val_loss: 0.2757 - val_acc: 0.8750\n",
      "Epoch 14/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1947 - acc: 0.9222 - val_loss: 0.3689 - val_acc: 0.8125\n",
      "Epoch 15/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1701 - acc: 0.9292 - val_loss: 0.4497 - val_acc: 0.7750\n",
      "Epoch 16/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1957 - acc: 0.9278 - val_loss: 0.2124 - val_acc: 0.9500\n",
      "Epoch 17/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1447 - acc: 0.9389 - val_loss: 0.1769 - val_acc: 0.9500\n",
      "Epoch 18/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1473 - acc: 0.9458 - val_loss: 0.3354 - val_acc: 0.8375\n",
      "Epoch 19/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1195 - acc: 0.9597 - val_loss: 0.4764 - val_acc: 0.7875\n",
      "Epoch 20/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1725 - acc: 0.9319 - val_loss: 0.2109 - val_acc: 0.9375\n",
      "Epoch 21/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1456 - acc: 0.9486 - val_loss: 0.2262 - val_acc: 0.9125\n",
      "Epoch 22/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1082 - acc: 0.9597 - val_loss: 0.2267 - val_acc: 0.9125\n",
      "Epoch 23/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1392 - acc: 0.9500 - val_loss: 0.3076 - val_acc: 0.8625\n",
      "Epoch 24/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1278 - acc: 0.9569 - val_loss: 0.2002 - val_acc: 0.9500\n",
      "Epoch 25/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1016 - acc: 0.9639 - val_loss: 0.2777 - val_acc: 0.8375\n",
      "Epoch 26/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1523 - acc: 0.9403 - val_loss: 0.2048 - val_acc: 0.8750\n",
      "Epoch 27/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1309 - acc: 0.9500 - val_loss: 0.1881 - val_acc: 0.9250\n",
      "Epoch 28/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1016 - acc: 0.9667 - val_loss: 0.1750 - val_acc: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8eb227deb8>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, Y_train, batch_size=batch_size, epochs=num_epochs, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 764us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3338590669631958, 0.88]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data, Y_test, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
