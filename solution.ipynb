{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По заданной выборке изображений составить бинарный классификатор, имеющий две категории: __Крокодилы__ и __Часы__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем пробовать несколько моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedShuffleSplit, train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor i in os.listdir(CROC_PATH):\\n    if DEBUG: print('Reading image `{}`'.format(i))\\n    arr = cv2.imread(CROC_PATH + i)\\n    croc_dict[i.replace('.png', '')] = arr\\n    croc_data = np.append(croc_data, arr)\\nfor i in os.listdir(CLOCK_PATH):\\n    arr = cv2.imread(CLOCK_PATH + i)\\n    clock_dict[i.replace('.png', '')] = arr\\n    np.append(croc_data, arr)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CROC_PATH = 'data/crocodile/'\n",
    "CLOCK_PATH = 'data/clock/'\n",
    "DEBUG = False\n",
    "croc_dict = dict()\n",
    "clock_dict = dict()\n",
    "croc_data = np.array([cv2.imread(CROC_PATH + i) for i in os.listdir(CROC_PATH)])\n",
    "clock_data = np.array([cv2.imread(CLOCK_PATH + i) for i in os.listdir(CLOCK_PATH)])\n",
    "'''\n",
    "for i in os.listdir(CROC_PATH):\n",
    "    if DEBUG: print('Reading image `{}`'.format(i))\n",
    "    arr = cv2.imread(CROC_PATH + i)\n",
    "    croc_dict[i.replace('.png', '')] = arr\n",
    "    croc_data = np.append(croc_data, arr)\n",
    "for i in os.listdir(CLOCK_PATH):\n",
    "    arr = cv2.imread(CLOCK_PATH + i)\n",
    "    clock_dict[i.replace('.png', '')] = arr\n",
    "    np.append(croc_data, arr)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим простые модели и оценим их качество."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейная модель (можно пропустить при выполнении кода)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = np.concatenate((np.ones(clock_data.shape[0]), np.zeros(croc_data.shape[0])))\n",
    "data = np.concatenate((clock_data.reshape(clock_data.shape[0], -1), croc_data.reshape(croc_data.shape[0], -1)))\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, ans, test_size=0.3, random_state=0)\n",
    "cv = StratifiedShuffleSplit(n_splits=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression(random_state=0)\n",
    "param_grid = {'penalty': ['l1', 'l2'], 'C': [1, 10, 100]}\n",
    "grid_cv = GridSearchCV(reg, param_grid, scoring='accuracy', cv=cv, n_jobs=4)\n",
    "%time grid_cv.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты не очень."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес (можно пропустить)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RandomForestClassifier(random_state=0, n_jobs=4)\n",
    "param_grid = {'n_estimators': [600],\n",
    "              'max_depth': [30], 'criterion': ['entropy']}\n",
    "grid_cv = GridSearchCV(reg, param_grid, scoring='accuracy', cv=cv, n_jobs=4)\n",
    "%time grid_cv.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный бустинг над случайными лесами (тоже можно пропустить)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = xgb.XGBClassifier(random_state=0, learning_rate=0.005, n_jobs=4, n_estimators=300)\n",
    "#param_grid = {'n_estimators': [100, 200, 400, 600],\n",
    "#              'learning_rate': [0.001, 0.005, 0.1]}\n",
    "param_grid = {'n_estimators': [400],\n",
    "              'learning_rate': [0.005]}\n",
    "grid_cv = GridSearchCV(reg, param_grid, scoring='accuracy', cv=cv, n_jobs=4)\n",
    "%time grid_cv.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(reg, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## А теперь изюминка нашего проекта: CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ans = np.concatenate((np.ones(clock_data.shape[0]), np.zeros(croc_data.shape[0])))\n",
    "data = np.concatenate((clock_data, croc_data))\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, ans, test_size=0.2, random_state=42)\n",
    "#cv = StratifiedShuffleSplit(n_splits=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры модели. С ними надо будет поиграться\n",
    "batch_size = 21\n",
    "num_epochs = 31\n",
    "kernel_size = 3\n",
    "pool_size = 2\n",
    "conv_depth_1 = 32\n",
    "conv_depth_2 = 32\n",
    "drop_prob_1 = 0.3\n",
    "drop_prob_2 = 0.4\n",
    "hidden_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train, depth, height, width = train_data.shape\n",
    "num_test = test_data.shape[0]\n",
    "num_classes = np.unique(train_labels).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.astype('float32')\n",
    "test_data = test_data.astype('float32')\n",
    "train_data /= np.max(train_data)\n",
    "test_data /= np.max(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(train_labels, num_classes)\n",
    "Y_test = np_utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(depth, height, width))\n",
    "\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "conv_1 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(inp)\n",
    "#conv_2 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_1)\n",
    "drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "conv_3 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(drop_1)\n",
    "#conv_4 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_3)\n",
    "drop_2 = Dropout(drop_prob_2)(pool_2)\n",
    "\n",
    "# Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
    "flat = Flatten()(drop_2)\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "out = Dense(num_classes, activation='softmax')(drop_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model = Model(input=inp, output=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adagrad', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720 samples, validate on 80 samples\n",
      "Epoch 1/31\n",
      "720/720 [==============================] - 2s 2ms/step - loss: 0.7592 - acc: 0.5792 - val_loss: 0.6880 - val_acc: 0.4875\n",
      "Epoch 2/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.6197 - acc: 0.6722 - val_loss: 0.6157 - val_acc: 0.6625\n",
      "Epoch 3/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.5328 - acc: 0.7444 - val_loss: 0.8739 - val_acc: 0.4375\n",
      "Epoch 4/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.4566 - acc: 0.7903 - val_loss: 0.4775 - val_acc: 0.7500\n",
      "Epoch 5/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.4032 - acc: 0.8208 - val_loss: 0.4128 - val_acc: 0.7625\n",
      "Epoch 6/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3616 - acc: 0.8403 - val_loss: 0.3712 - val_acc: 0.8625\n",
      "Epoch 7/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3964 - acc: 0.8375 - val_loss: 0.3061 - val_acc: 0.8750\n",
      "Epoch 8/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.3020 - acc: 0.8833 - val_loss: 0.2918 - val_acc: 0.9000\n",
      "Epoch 9/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.2859 - acc: 0.8917 - val_loss: 0.2615 - val_acc: 0.9000\n",
      "Epoch 10/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.2855 - acc: 0.8875 - val_loss: 0.3346 - val_acc: 0.8250\n",
      "Epoch 11/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.2433 - acc: 0.8944 - val_loss: 0.2478 - val_acc: 0.8875\n",
      "Epoch 12/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.2252 - acc: 0.9069 - val_loss: 0.2547 - val_acc: 0.8750\n",
      "Epoch 13/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.2285 - acc: 0.9153 - val_loss: 0.2530 - val_acc: 0.9000\n",
      "Epoch 14/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.2131 - acc: 0.9125 - val_loss: 0.4223 - val_acc: 0.7750\n",
      "Epoch 15/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1947 - acc: 0.9208 - val_loss: 0.2310 - val_acc: 0.9250\n",
      "Epoch 16/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.2023 - acc: 0.9181 - val_loss: 0.2459 - val_acc: 0.8875\n",
      "Epoch 17/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1906 - acc: 0.9222 - val_loss: 0.2596 - val_acc: 0.8750\n",
      "Epoch 18/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1767 - acc: 0.9361 - val_loss: 0.3900 - val_acc: 0.7875\n",
      "Epoch 19/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1584 - acc: 0.9417 - val_loss: 0.2139 - val_acc: 0.9375\n",
      "Epoch 20/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1819 - acc: 0.9333 - val_loss: 0.2405 - val_acc: 0.9125\n",
      "Epoch 21/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1628 - acc: 0.9333 - val_loss: 0.2197 - val_acc: 0.9125\n",
      "Epoch 22/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1628 - acc: 0.9444 - val_loss: 0.2864 - val_acc: 0.8500\n",
      "Epoch 23/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1367 - acc: 0.9500 - val_loss: 0.1950 - val_acc: 0.9250\n",
      "Epoch 24/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1320 - acc: 0.9569 - val_loss: 0.3721 - val_acc: 0.8125\n",
      "Epoch 25/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1351 - acc: 0.9528 - val_loss: 0.3197 - val_acc: 0.8250\n",
      "Epoch 26/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1374 - acc: 0.9472 - val_loss: 0.2988 - val_acc: 0.8625\n",
      "Epoch 27/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1591 - acc: 0.9292 - val_loss: 0.2621 - val_acc: 0.8625\n",
      "Epoch 28/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1410 - acc: 0.9556 - val_loss: 0.2277 - val_acc: 0.9125\n",
      "Epoch 29/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1112 - acc: 0.9625 - val_loss: 0.2997 - val_acc: 0.8500\n",
      "Epoch 30/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1253 - acc: 0.9611 - val_loss: 0.1960 - val_acc: 0.9250\n",
      "Epoch 31/31\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1139 - acc: 0.9514 - val_loss: 0.1647 - val_acc: 0.9250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f18a8421710>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, Y_train, batch_size=batch_size, epochs=num_epochs, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 802us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.28968769788742066, 0.905]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data, Y_test, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
