{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedShuffleSplit, train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor i in os.listdir(CROC_PATH):\\n    if DEBUG: print('Reading image `{}`'.format(i))\\n    arr = cv2.imread(CROC_PATH + i)\\n    croc_dict[i.replace('.png', '')] = arr\\n    croc_data = np.append(croc_data, arr)\\nfor i in os.listdir(CLOCK_PATH):\\n    arr = cv2.imread(CLOCK_PATH + i)\\n    clock_dict[i.replace('.png', '')] = arr\\n    np.append(croc_data, arr)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CROC_PATH = 'data/crocodile/'\n",
    "CLOCK_PATH = 'data/clock/'\n",
    "DEBUG = False\n",
    "croc_dict = dict()\n",
    "clock_dict = dict()\n",
    "croc_data = np.array([cv2.imread(CROC_PATH + i) for i in os.listdir(CROC_PATH)])\n",
    "clock_data = np.array([cv2.imread(CLOCK_PATH + i) for i in os.listdir(CLOCK_PATH)])\n",
    "'''\n",
    "for i in os.listdir(CROC_PATH):\n",
    "    if DEBUG: print('Reading image `{}`'.format(i))\n",
    "    arr = cv2.imread(CROC_PATH + i)\n",
    "    croc_dict[i.replace('.png', '')] = arr\n",
    "    croc_data = np.append(croc_data, arr)\n",
    "for i in os.listdir(CLOCK_PATH):\n",
    "    arr = cv2.imread(CLOCK_PATH + i)\n",
    "    clock_dict[i.replace('.png', '')] = arr\n",
    "    np.append(croc_data, arr)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим простые модели и оценим их качество."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейная модель (можно пропустить при выполнении кода)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = np.concatenate((np.ones(clock_data.shape[0]), np.zeros(croc_data.shape[0])))\n",
    "data = np.concatenate((clock_data.reshape(clock_data.shape[0], -1), croc_data.reshape(croc_data.shape[0], -1)))\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, ans, test_size=0.3, random_state=0)\n",
    "cv = StratifiedShuffleSplit(n_splits=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression(random_state=0)\n",
    "param_grid = {'penalty': ['l1', 'l2'], 'C': [1, 10, 100]}\n",
    "grid_cv = GridSearchCV(reg, param_grid, scoring='accuracy', cv=cv, n_jobs=4)\n",
    "%time grid_cv.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты не очень. Попробуем другие классификаторы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RandomForestClassifier(random_state=0, n_jobs=4)\n",
    "param_grid = {'n_estimators': [600],\n",
    "              'max_depth': [30], 'criterion': ['entropy']}\n",
    "grid_cv = GridSearchCV(reg, param_grid, scoring='accuracy', cv=cv, n_jobs=4)\n",
    "%time grid_cv.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный бустинг над случайными лесами (тоже можно пропустить)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = xgb.XGBClassifier(random_state=0, learning_rate=0.005, n_jobs=4, n_estimators=300)\n",
    "#param_grid = {'n_estimators': [100, 200, 400, 600],\n",
    "#              'learning_rate': [0.001, 0.005, 0.1]}\n",
    "param_grid = {'n_estimators': [400],\n",
    "              'learning_rate': [0.005]}\n",
    "grid_cv = GridSearchCV(reg, param_grid, scoring='accuracy', cv=cv, n_jobs=4)\n",
    "%time grid_cv.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(reg, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## А теперь изюминка нашего проекта: CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ans = np.concatenate((np.ones(clock_data.shape[0]), np.zeros(croc_data.shape[0])))\n",
    "data = np.concatenate((clock_data, croc_data))\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, ans, test_size=0.2, random_state=42)\n",
    "#cv = StratifiedShuffleSplit(n_splits=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры модели. С ними надо будет поиграться\n",
    "batch_size = 15\n",
    "num_epochs = 28\n",
    "kernel_size = 3\n",
    "pool_size = 2\n",
    "conv_depth_1 = 32\n",
    "conv_depth_2 = 32\n",
    "drop_prob_1 = 0.3\n",
    "drop_prob_2 = 0.4\n",
    "hidden_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train, depth, height, width = train_data.shape\n",
    "num_test = test_data.shape[0]\n",
    "num_classes = np.unique(train_labels).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.astype('float32')\n",
    "test_data = test_data.astype('float32')\n",
    "train_data /= np.max(train_data)\n",
    "test_data /= np.max(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(train_labels, num_classes)\n",
    "Y_test = np_utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(depth, height, width))\n",
    "\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "conv_1 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(inp)\n",
    "#conv_2 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_1)\n",
    "drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "conv_3 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(drop_1)\n",
    "#conv_4 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(conv_3)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_3)\n",
    "drop_2 = Dropout(drop_prob_2)(pool_2)\n",
    "\n",
    "# Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
    "flat = Flatten()(drop_2)\n",
    "hidden = Dense(hidden_size, activation='tanh')(flat)\n",
    "drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "out = Dense(num_classes, activation='softmax')(drop_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model = Model(input=inp, output=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adagrad', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720 samples, validate on 80 samples\n",
      "Epoch 1/28\n",
      "720/720 [==============================] - 2s 2ms/step - loss: 0.5713 - acc: 0.8764 - val_loss: 0.3036 - val_acc: 0.9000\n",
      "Epoch 2/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1294 - acc: 0.9444 - val_loss: 0.2382 - val_acc: 0.9125\n",
      "Epoch 3/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.1199 - acc: 0.9542 - val_loss: 0.2476 - val_acc: 0.8875\n",
      "Epoch 4/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.0872 - acc: 0.9681 - val_loss: 0.3475 - val_acc: 0.8375\n",
      "Epoch 5/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.0936 - acc: 0.9639 - val_loss: 0.3223 - val_acc: 0.8625\n",
      "Epoch 6/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.0731 - acc: 0.9708 - val_loss: 0.2767 - val_acc: 0.9125\n",
      "Epoch 7/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.0574 - acc: 0.9792 - val_loss: 0.1969 - val_acc: 0.9125\n",
      "Epoch 8/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.0944 - acc: 0.9681 - val_loss: 0.2641 - val_acc: 0.9000\n",
      "Epoch 9/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.0760 - acc: 0.9750 - val_loss: 0.2613 - val_acc: 0.9000\n",
      "Epoch 10/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.0823 - acc: 0.9667 - val_loss: 0.2810 - val_acc: 0.8750\n",
      "Epoch 11/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.0704 - acc: 0.9694 - val_loss: 0.2924 - val_acc: 0.8500\n",
      "Epoch 12/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.0631 - acc: 0.9736 - val_loss: 0.1877 - val_acc: 0.9250\n",
      "Epoch 13/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.0606 - acc: 0.9833 - val_loss: 0.2306 - val_acc: 0.9375\n",
      "Epoch 14/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.0548 - acc: 0.9806 - val_loss: 0.2196 - val_acc: 0.9125\n",
      "Epoch 15/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.0540 - acc: 0.9792 - val_loss: 0.1845 - val_acc: 0.9375\n",
      "Epoch 16/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.0609 - acc: 0.9750 - val_loss: 0.2096 - val_acc: 0.9375\n",
      "Epoch 17/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.0570 - acc: 0.9792 - val_loss: 0.2006 - val_acc: 0.9250\n",
      "Epoch 18/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.0606 - acc: 0.9722 - val_loss: 0.1803 - val_acc: 0.9125\n",
      "Epoch 19/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.0454 - acc: 0.9833 - val_loss: 0.3146 - val_acc: 0.8750\n",
      "Epoch 20/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.0565 - acc: 0.9750 - val_loss: 0.2287 - val_acc: 0.9125\n",
      "Epoch 21/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.0470 - acc: 0.9847 - val_loss: 0.2322 - val_acc: 0.9250\n",
      "Epoch 22/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.0446 - acc: 0.9847 - val_loss: 0.2650 - val_acc: 0.9125\n",
      "Epoch 23/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.0332 - acc: 0.9903 - val_loss: 0.2402 - val_acc: 0.9125\n",
      "Epoch 24/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.0415 - acc: 0.9875 - val_loss: 0.2729 - val_acc: 0.9125\n",
      "Epoch 25/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.0450 - acc: 0.9861 - val_loss: 0.2504 - val_acc: 0.9250\n",
      "Epoch 26/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.0511 - acc: 0.9833 - val_loss: 0.2105 - val_acc: 0.9375\n",
      "Epoch 27/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.0368 - acc: 0.9847 - val_loss: 0.2309 - val_acc: 0.9250\n",
      "Epoch 28/28\n",
      "720/720 [==============================] - 1s 2ms/step - loss: 0.0363 - acc: 0.9875 - val_loss: 0.2205 - val_acc: 0.9125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f18dc14d470>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, Y_train, batch_size=batch_size, epochs=num_epochs, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 828us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4358933484554291, 0.9]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data, Y_test, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
